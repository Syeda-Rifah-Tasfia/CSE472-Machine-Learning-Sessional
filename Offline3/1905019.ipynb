{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as ds\n",
    "from sklearn import datasets\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, inputDimensions, outputDimensions):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.weights = np.random.randn(outputDimensions, inputDimensions)\n",
    "        self.biases = np.zeros((outputDimensions, 1))\n",
    "\n",
    "    def forwardPass(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.dot(self.weights, input) + self.biases\n",
    "        return self.output\n",
    "    \n",
    "    def backwardPass(self, dL_dout, alpha):\n",
    "        dw = np.dot(dL_dout, self.input.T)\n",
    "        db = np.sum(dL_dout, axis=1, keepdims=True)\n",
    "\n",
    "        di = np.dot(self.weights.T, dL_dout)\n",
    "\n",
    "        self.weights -= alpha * dw\n",
    "        self.biases -= alpha * db\n",
    "\n",
    "        return di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RELU:\n",
    "    ## matrix that passes through relu is (n[l], m)\n",
    "    def forwardPass(self, x):\n",
    "        self.input = x\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backwardPass(self, x):\n",
    "        return x * (self.input > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def calcSoftmax(self, Y):\n",
    "        #calculate from an 1D array\n",
    "        exps = np.exp(Y - np.max(Y, axis=0, keepdims=True))\n",
    "        return exps / np.sum(exps, axis=0, keepdims=True)\n",
    "    \n",
    "    def forwardPass(self, Y):\n",
    "        return self.calcSoftmax(Y)\n",
    "    \n",
    "    def backwardPass(self, Y):\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyLoss(y, y_hat):\n",
    "    return -np.sum(y * np.log(y_hat + 1e-9)) / y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loaders:\n",
    "    #train a 3 hidden layer neural network\n",
    "    def train_data(self, epochs, alpha, input_dimensions, output_dimensions, train_loader, dense1, activation1, dense2, activation2, dense3, activation3, dense4):\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                total_loss = 0\n",
    "                images = images.view(images.size(0), -1).numpy()\n",
    "                labels_onehot = np.eye(output_dimensions)[labels.numpy()]\n",
    "\n",
    "                #forward pass\n",
    "                dense1_output = dense1.forwardPass(images.T)\n",
    "                activation1_output = activation1.forwardPass(dense1_output)\n",
    "                dense2_output = dense2.forwardPass(activation1_output)\n",
    "                activation2_output = activation2.forwardPass(dense2_output)\n",
    "                dense3_output = dense3.forwardPass(activation2_output)\n",
    "                activation3_output = activation3.forwardPass(dense3_output)\n",
    "                dense4_output = dense4.forwardPass(activation3_output)\n",
    "                \n",
    "                y_pred = Softmax().calcSoftmax(dense4_output)\n",
    "\n",
    "                #calculate loss\n",
    "                loss = crossEntropyLoss(labels_onehot, y_pred.T)\n",
    "                total_loss += loss\n",
    "\n",
    "                #backward pass\n",
    "                loss_gradient = y_pred.T - labels_onehot\n",
    "                dh4 = dense4.backwardPass(loss_gradient.T, alpha)\n",
    "                do4 = activation3.backwardPass(dh4)\n",
    "                dh3 = dense3.backwardPass(do4, alpha)\n",
    "                do3 = activation2.backwardPass(dh3)\n",
    "                dh2 = dense2.backwardPass(do3, alpha)\n",
    "                do2 = activation1.backwardPass(dh2)\n",
    "                dh1 = dense1.backwardPass(do2, alpha)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def test_data(self, test_loader, dense1, activation1, dense2, activation2, dense3, activation3, dense4):\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1).numpy()\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            #write like train\n",
    "            \n",
    "            dense1_output = dense1.forwardPass(images.T)\n",
    "            activation1_output = activation1.forwardPass(dense1_output)\n",
    "            dense2_output = dense2.forwardPass(activation1_output)\n",
    "            activation2_output = activation2.forwardPass(dense2_output)\n",
    "            dense3_output = dense3.forwardPass(activation2_output)\n",
    "            activation3_output = activation3.forwardPass(dense3_output)\n",
    "            dense4_output = dense4.forwardPass(activation3_output)\n",
    "            y_pred = Softmax().calcSoftmax(dense4_output)\n",
    "\n",
    "            predictions = np.argmax(y_pred, axis=0)\n",
    "            correct += np.sum(predictions == labels)\n",
    "            total += labels.shape[0]\n",
    "\n",
    "        # print upto 6 after decimal\n",
    "        print(f\"Accuracy: {correct/total*100:.6f}\")\n",
    "\n",
    "    def savetoPickle(self, dense1, dense2, dense3, dense4, filename):\n",
    "        weghts_and_biases = {\n",
    "            \"dense1_weights\": dense1.weights,\n",
    "            \"dense1_biases\": dense1.biases,\n",
    "            \"dense2_weights\": dense2.weights,\n",
    "            \"dense2_biases\": dense2.biases,\n",
    "            \"dense3_weights\": dense3.weights,\n",
    "            \"dense3_biases\": dense3.biases,\n",
    "            \"dense4_weights\": dense4.weights,\n",
    "            \"dense4_biases\": dense4.biases\n",
    "        }\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(weghts_and_biases, file)\n",
    "\n",
    "        print(\"Saved to pickle file\")\n",
    "\n",
    "    def loadfromPickle(self, filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            weights_and_biases = pickle.load(file)\n",
    "\n",
    "        dense1 = DenseLayer(28*28, 32)\n",
    "        dense1.weights = weights_and_biases[\"dense1_weights\"]\n",
    "        dense1.biases = weights_and_biases[\"dense1_biases\"]\n",
    "\n",
    "        dense2 = DenseLayer(32, 32)\n",
    "        dense2.weights = weights_and_biases[\"dense2_weights\"]\n",
    "        dense2.biases = weights_and_biases[\"dense2_biases\"]\n",
    "\n",
    "        dense3 = DenseLayer(32, 32)\n",
    "        dense3.weights = weights_and_biases[\"dense3_weights\"]\n",
    "        dense3.biases = weights_and_biases[\"dense3_biases\"]\n",
    "\n",
    "        dense4 = DenseLayer(32, 10)\n",
    "        dense4.weights = weights_and_biases[\"dense4_weights\"]\n",
    "        dense4.biases = weights_and_biases[\"dense4_biases\"]\n",
    "\n",
    "        return dense1, dense2, dense3, dense4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./FMNIST', train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./FMNIST', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four layers\n",
    "loaders = Loaders()\n",
    "\n",
    "input_dimensions = 28*28\n",
    "output_dimensions = 10\n",
    "numOfNeurons = 32\n",
    "\n",
    "epochs = 5\n",
    "learnRate = 0.005\n",
    "\n",
    "dense1 = DenseLayer(input_dimensions, numOfNeurons)\n",
    "activation1 = RELU()\n",
    "dense2 = DenseLayer(numOfNeurons, numOfNeurons)\n",
    "activation2 = RELU()\n",
    "dense3 = DenseLayer(numOfNeurons, numOfNeurons)\n",
    "activation3 = RELU()\n",
    "dense4 = DenseLayer(numOfNeurons, output_dimensions)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 7.390249121266374\n",
      "Epoch: 1, Loss: 7.374932262318621\n",
      "Epoch: 2, Loss: 7.383546259834754\n",
      "Epoch: 3, Loss: 7.362393289456287\n",
      "Epoch: 4, Loss: 7.380455976619778\n"
     ]
    }
   ],
   "source": [
    "loaders.train_data(epochs, learnRate, input_dimensions, output_dimensions, train_loader, dense1, activation1, dense2, activation2, dense3, activation3, dense4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.000000\n"
     ]
    }
   ],
   "source": [
    "loaders.test_data(test_loader, dense1, activation1, dense2, activation2, dense3, activation3, dense4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to pickle file\n"
     ]
    }
   ],
   "source": [
    "filename = \"1905019.pkl\"\n",
    "loaders.savetoPickle(dense1, dense2, dense3, dense4, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.DenseLayer at 0x7ff4e4b1a010>,\n",
       " <__main__.DenseLayer at 0x7ff4d8392410>,\n",
       " <__main__.DenseLayer at 0x7ff4d80626d0>,\n",
       " <__main__.DenseLayer at 0x7ff4d84f9a50>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.loadfromPickle(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
